A Brief Introduction to Markov Chains

Markov chains are one of the most important tools for modelling stochastic processes. This talk will give an introduction to what are Markov chains, and give simple examples of how they are used. Discrete and contiuous time Markov chains, absorbing chains and higher order chains will be shown. Examples will be shown by modelling board games and queues.